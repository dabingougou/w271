---
title: "W271 Assignment 8"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r load packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(patchwork)

library(lubridate)

library(tsibble)
library(feasts)
library(forecast)

library(sandwich)
library(lmtest)

library(nycflights13)
library(blsR)

library(fable)
```

```{r set themes}
theme_set(theme_minimal())
```


# (14 points total) Question-1: Is Unemployment an Autoregressive or a Moving Average Process? 

You did work in a previous homework to produce a data pipeline that pulled the unemployment rate from official BLS sources. Reuse that pipeline to answer this final question in the homework: 

> "Are unemployment claims in the US an autoregressive or a moving average process?

\newpage
## (1 point) Part-1: Why is the distinction important? 

Why is it important to know whether a process is a $AR$ or an $MA$ (or a combination of the two) process? What changes in the ways that you would talk about the process, what changes in the ways that you would fit a model to the process, and what changes with how you would produce a forecast for this process?

### Q1P1 Answer 

**Knowing whether a process is AR, MA, or a mix matters because it defines how persistence and shocks drive the series and how we model and forecast it.**

Interpretation:

 - AR: current values depend on past values (persistence).

 - MA: current values depend on past shocks (transitory effects).

Forecasting:AR forecasts rely on past predicted values; MA forecasts decay faster as past shocks fade. Correctly identifying the process ensures accurate model specification and reliable forecasts.


\newpage
## (1 point) Part-2: Pull in (and clean up) your data pipeline. 

In the previous homework, you built a data pipeline to draw data from the BLS. We are asking you to re-use, and if you think it is possible, to improve the code that you wrote for this pipeline in the previous homework. 

- Are there places where you took "shortcuts" that could be more fully developed?

- Are the processes that could be made more modular, or better documented so that they are easier for you to understand what they are doing? You've been away from the code that you wrote for a few weeks, and so it might feel like "discovering" the code of a *mad-person* (Who even wrote this???)

### Answer


```{r}

huibin_bls_key <- "e943ccb8989f4599bd7964149a31457d"
bls_set_key(huibin_bls_key)
if (bls_has_key()) {
  print("Key provided. OK.")
} else {
  print("BLS API key not provided")
}

# Specify series IDs
series_id_list <- c(
  overall = "LNS14000000",
  male    = "LNS14000001",
  female  = "LNS14000002"
)

current_year <- as.numeric(format(Sys.Date(), "%Y"))
current_year

#raw_bls_data <- get_n_series_table(
#  series_ids = series_id_list,
#  api_key = bls_get_key(),
#  start_year = current_year - 20, 
#  end_year = current_year
#)

# Saved the query results so that I don't use up my api quota
#saveRDS(raw_bls_data, file = "data/my_api_results.Rds")

raw_bls_data <- readRDS("data/my_api_results.Rds")

# bls_unset_key()

head(raw_bls_data)

unemployment <- 
  raw_bls_data %>%
  pivot_longer(
#    cols = c("LNS14000000", "LNS14000001"), 
    cols = starts_with("LNS"),
    names_to = "series_id",
    values_to = "value"
  ) %>%
  mutate(
    date = lubridate::ymd(paste0(year, 
                                 "-", 
                                 gsub(pattern = "M", 
                                      replacement = "",
                                      x = period),
                                 "-01"
                                 )), 
    name = case_when(
      series_id == "LNS14000000" ~ "overall",
      series_id == "LNS14000001" ~ "male",
      series_id == "LNS14000002" ~ "female",
      TRUE ~ series_id
                      )
  ) %>%
  mutate(
    year = year(date),
    month = month(date),
    time_index = yearmonth(date)
  ) %>%
  as_tsibble(
    key = name,
    index = time_index
  )

unemployment
unemployment %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line(line_width = 1)

# After examining all three, which are similar, I keep the overall unemployment rate
unemployment <-
  unemployment %>%
  filter(name == "overall")
```

\newpage
## (5 points) Part-3: Conduct an EDA of the data and comment on what you see. 

We have presented four **core** plots that are a part of the EDA for time-serires data. Produce each of these plots, and comment on what you see.

```{r}

unemployment %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line(linewidth = 1) + 
  labs(
    title = "2005 - 2025 Unemployment by Gender",
    x = "Time",
    color = "Series"
  )

#unemployment %>%
#  autoplot(value)

# Second: ACF Plot
unemployment %>%
#  filter(name == "overall") %>%
  ACF(
    lag_max= 60
  ) %>%
  autoplot() + 
  labs(
    title = "ACF for Overall Unemployment",
    x = "Lag in Month"
  )

# Third: Distribution
unemployment %>%
#  filter(name == "overall") %>%
  ggplot(aes(x = value)) + 
  geom_histogram(bins = 80)

# Forth: PACF
unemployment %>%
  filter(name == "overall") %>%
  PACF(value, lag_max = 60) %>%
  autoplot() + 
  labs(title = "PACF for Overall Unemployment",
       x = "Lag in Month")

```

\newpage
## (1 point) Part-4: Make a Call 


Based on what you have plotted and written down in the previous section, would you say that the unemployment rate is an $AR$, $MA$ or a mix of the two?

### Answer

**The unemployment rate time series, according to the EDA, particularly the ACF and the PACF, resembles as an AR(1) process. Specifically, autocorrelation decays gradually, PACF cuts off sharply after lag 1 — meaning each month’s unemployment rate is strongly predicted by the previous month’s rate.**

**Also I am using my knowledge from macroeconomics that long-run unemployment should be, in theory, a constant, or the natural rate unemployment rate under potential output. This favors the assumption that the time series is a stationary process.**

\newpage
## (6 points total) Part-5:  Estimate a model 

Report the best-fitting parameters from the best-fitting model, and then describe what your model is telling you. In this description, you should: 

- (1 point) State, and justify your model selection criteria. 

### Answer

```{r}
unemployment

model <- 
  unemployment %>%
  pull(value) %>%
  ar(aic = TRUE, bic = TRUE, order.max = 12, method = "yule-walker")

model$order
model$aic
model$ar
sqrt(model$asy.var.coef)
model$asy.var
summary(model)
model$bic
model$resid
?ar()


# Extract and compare AICc values
#model_comparison <- glance(fit_ar_models) %>%
#  select(.model, AICc, BIC) %>%
#  arrange(AICc)

#model_comparison
```

\newpage
- (1 point) Interpret the model selection criteria in context of the other models that you also fitted.

### Answer
**Using the ar() function similarly to the async, the AR(1) model was selected as the best-fitting model because it had the lowest AIC (0 in the normalized output) among all tested orders (p=0 to p=12).**

**Interpretation: The AR(1) model is the most parsimonious (simplest adequate) model for the unemployment rate under the assumption of stationarity. It suggests that the predictive power of the unemployment time series is captured by its immediate prior value y(t−1), and adding more lagged terms y(t−2), y(t−3) and so on does not improve the fit enough to justify the increased complexity (parameter count). This result is consistent with the sharp cutoff seen at Lag 1 in the PACF plot.**

\newpage
- (2 points) Interpret the coefficients of the model that you have estimated. 

### Answer

Interpretation:

**AR(1) Coefficient ($\phi_1$=0.9416): This coefficient is highly significant (since 0.9416 is many standard errors away from 0).**

**It measures persistence. A value of 0.9416 means that 94.16% of last month's unemployment rate persists into the current month. The current unemployment rate is strongly driven by the rate in the immediately preceding period. This high value confirms the slow, smooth movement observed in the time plot and ACF.**

\newpage
- (2 points) Produce and interpret the model diagnostic plots to evaluate how well your best-fitting model is performing.

### Answer

Ljung-Box test results and the ACF graph of the residuals are shown below in the code chunk.

**With Ljung-Box test, the p-value is 0.95 and we fail to reject the null hypothesis that the residuals are white noise. This confirms the visual evidence from the ACF plot that the AR(1) model is statistically adequate and fits the data well under the assumption of stationarity.**

**The ACF plot shows no significant spikes at any lag (Lags 1 through 20 are all within the blue dashed confidence intervals). The AR(1) model has successfully captured the linear autocorrelation in the original unemployment series. The residuals appear to be a sequence of white noise.**

```{r}
ar_residuals <- model$resid

hist(ar_residuals)


plot.ts(ar_residuals, 
        main = "Time Trend of AR(1) Residuals", 
        ylab = "Residuals", 
        xlab = "Time")

Box.test(ar_residuals, lag = 12, type = "Ljung-Box")

acf(ar_residuals, 
    na.action = na.pass,
    main = "ACF of AR(1) Residuals")
```

\newpage
- (1 (optional) point) If, after fitting the models, and interpreting their diagnostics plots, you determine that the model is doing poorly -- for example, you notice that the residuals are not following a white-noise process -- then, make a note of the initial model that you fitted then propose a change to the data or the model in order to make the model fit better. If you take this action, you should focus your interpretation of the model's coefficients on the model that you think does the best job, which might be the model after some form of variable transformation. 

### Answer

**Diagnostics from the previous part shows that the model is fitting well. **


\newpage
# (14 Points Total) Question-2: Forecasting Inflation

The Federal Reserve tracks inflation data across countries on a monthly level.

\newpage
## (1 point) Part-1: Load and Clean Data

Load the CSV provided and store the data in a useful dataframe. Check for missing values and outliers in the data. Perform any cleaning that is necessary.

Also create lagged columns for GBR and CAN and training and test datasets based on pre and post Jan 1, 2022.

### Answer
```{r}
raw_inflation <- read_csv("data/inflation_country.csv")

dim(raw_inflation)

sum(is.na(raw_inflation))

#raw_inflation

# raw_inflation %>%
#   select(date, USA, GBR, CAN) %>%
#   mutate(
#     date = as_date(date),
#     GBR_lag1 = lag(GBR, 1),
#     CAN_lag1 = lag(CAN, 1)
#   ) %>%
#   pivot_longer(
#     cols = -date,
#     names_to = "country",
#     values_to = "value"
#   ) %>%
#   as_tsibble(
#     key = country,
#     index = date
#   ) 




# 1. Load the original wide data and select the required columns
inflation_arimax_data <- 
  raw_inflation %>%
  select(date, USA, GBR, CAN) %>%
  mutate(date = yearmonth(date)) %>%
  # Convert to tsibble early for easy lag calculation
  as_tsibble(index = date) %>%
  
  # 2. Create the lagged variables DIRECTLY on the wide data
  mutate(
    GBR_lag1 = lag(GBR, 1),
    CAN_lag1 = lag(CAN, 1)
  )

# 3. Create Train and Test Datasets (Split at Jan 1, 2022)
split_date <- ymd("2022-01-01")

# Training data
train_data <- 
  inflation_arimax_data %>%
  filter(date < split_date)

# Test data
test_data <- 
  inflation_arimax_data %>%
  filter(date >= split_date)

train_data
test_data

# Display the dimensions to verify the split
print(paste("Train Data Rows:", nrow(train_data)))
print(paste("Test Data Rows:", nrow(test_data)))

# 4. Save the new train/test data (overwriting previous files)
#write_csv(train_data_v2, "inflation_train_data.csv")
#write_csv(test_data_v2, "inflation_test_data.csv")
```

\newpage
## (5 points) Part-2: Produce a Model on the Training Data

1. Select inflation data for the US.
2. Produce a 7 observation lag, backward smoother of inflation and plot the original time series with its smoothed trend. 
3. Produce a time series model of inflation. This should include: 
  - Conducting a full EDA and description of the data that you observe.
  - Estimating a model that you believe is appropriate after conducting your EDA.
  - Evaluating the model performance through diagnostic plots and making any necessary adjustments to satisfy key assumptions.

### Answer

\newpage
Smoother and the EDA. 

ACF Plot (left):

The ACF declines slowly and smoothly from 1.0 toward 0, taking many lags (over 24 months) to taper off.

This gradual decay indicates strong persistence — each month’s inflation rate is highly correlated with many months prior.

Such slow decay suggests an autoregressive (AR) component rather than a pure moving-average (MA) one.

PACF Plot (right):

The PACF has a large spike at lag 1, followed by much smaller and statistically insignificant spikes.

This pattern — PACF cuts off after lag 1 while ACF decays gradually — is the textbook signature of an AR(1) process.

Visual check (smoothed plot):

Inflation has long cycles (multi-year swings) and persistent trends rather than sharp, short-run oscillations.

That visually reinforces the conclusion that inflation is highly persistent and well captured by an AR model.

Given these diagnostics, we’ll start by estimating an AR(1) model for U.S. inflation using the training data, and then we’ll test whether a higher-order AR (e.g., AR(2) or AR(3)) or an ARIMA with differencing gives any improvement.

```{r}
library(slider)

train_data_smoothed <- 
  train_data %>%
  select(USA) %>%
  mutate(
    US_smoother = slide_dbl(
      .x = USA,
      .f = mean,
      .before = 6,
      .after = 0,
      .complete = FALSE
    )
  )

#class(train_data_smoothed)

smoother_plot <- train_data_smoothed %>%
  ggplot(aes(x = date)) +
  geom_line(aes(y = USA, color = "Original USA Inflation")) +
  geom_line(aes(y = US_smoother, color = "7-Month Backward Smoother"), linewidth = 1) +
  labs(
    title = "USA Inflation Rate: Original Series vs. 7-Month Smoothed Trend",
    y = "Inflation Rate (%)",
    x = "Year",
    color = "Series"
  ) +
  scale_color_manual(values = c("Original USA Inflation" = "gray50", "7-Month Backward Smoother" = "blue")) +
  theme_minimal()

smoother_plot

us_train <- train_data %>%
select(date, USA) %>%
as_tsibble(index = date)

sum(is.na(train_data$USA))

acf_us <- us_train %>% ACF(USA, lag_max = 60)
pacf_us <- us_train %>% PACF(USA, lag_max = 60)

p_acf <- autoplot(acf_us) +
labs(title = "ACF: USA Inflation (Training Set)",
x = "Lag (months)", y = "Autocorrelation")

p_pacf <- autoplot(pacf_us) +
labs(title = "PACF: USA Inflation (Training Set)",
x = "Lag (months)", y = "Partial Autocorrelation")

p_acf + p_pacf


```

\newpage
### Q2 Part 2 - continued 
**Estimating a model**

The code block below shows the estimated model. The ar() selects AR(1). "order" in summary of the fitted model is 1, but "ar" in summary is 25. This is because order 25 gives the smallest aic (normalized to 0, same as the async). 

With some googling and ChatGPTing around, the most plausible explanation is that sometimes with highly persistent data (like inflation), the yule-walker algorithm overfits at higher orders — it keeps adding lags until it “almost perfectly fits” the data, driving the AIC down. 
```{r}
usa_infl_ar1 <- train_data %>%
select(date, USA) %>%
  ar()

summary(usa_infl_ar1)

usa_infl_ar1$aic
```
\newpage
### Q2 Part 2 step 3

**Evaluating the model performance through diagnostic plots and making any necessary adjustments to satisfy key assumptions.**

As the code block below shows: 

1. Residual time plot
The residuals fluctuate randomly around zero without any visible trends or structural breaks. This indicates the mean equation is probably well specified.

2. Histogram
Residuals are approximately bell-shaped and symmetric around zero. This suggests the normality assumption for AR(1) errors is likely reasonable.

3. ACF and PACF of residuals
No spikes exceed the blue 95 % confidence bands beyond lag 0. This means no significant serial correlation remains visually.

4. Ljung–Box test
p-value is 0.0004 < 0.05, and we reject the null. Statistically, there is autocorrelation left in the residuals even though it’s small visually.




Overall, this AR(1) model captures most of the serial dependence, but not all.

To address this, a natural adjustment is to allow for additional autoregressive lags (as shown in the second code chunk below) but the Ljung-Box test still comes back rejecting the null. 

So, perhaps the stationary assumption needs to be adjusted. I stopped here for Q2 Part 2.
```{r}

#Extract residuals
ar1_resid <- usa_infl_ar1$resid

#Plot residuals over time
plot.ts(ar1_resid,
main = "AR(1) Residuals Over Time",
ylab = "Residuals",
xlab = "Time")

#Histogram of residuals
hist(ar1_resid, breaks = 30,
main = "Histogram of AR(1) Residuals",
xlab = "Residuals")

#ACF of residuals
acf(ar1_resid, na.action = na.pass,
main = "ACF of AR(1) Residuals")

#PACF of residuals
pacf(ar1_resid, na.action = na.pass,
main = "PACF of AR(1) Residuals")

#Ljung-Box test for white noise
Box.test(ar1_resid, lag = 12, type = "Ljung-Box")

```

```{r}
usa_infl_ar3 <- train_data %>%
select(date, USA) %>%
  ar(order.max = 3)

summary(usa_infl_ar3)

#Extract residuals
ar3_resid <- usa_infl_ar3$resid

#Plot residuals over time
plot.ts(ar3_resid,
main = "AR(3) Residuals Over Time",
ylab = "Residuals",
xlab = "Time")

#Histogram of residuals
hist(ar3_resid, breaks = 30,
main = "Histogram of AR(3) Residuals",
xlab = "Residuals")

#ACF of residuals
acf(ar3_resid, na.action = na.pass,
main = "ACF of AR(3) Residuals")

#PACF of residuals
pacf(ar3_resid, na.action = na.pass,
main = "PACF of AR(3) Residuals")

#Ljung-Box test for white noise
Box.test(ar3_resid, lag = 12, type = "Ljung-Box")


```
## (5 points) Part-3: Leveraging Other Countries

1. Examine how correlated (lagged) GBR and CAN inflation is with the US. Do you think prior inflation data in these countries can help forecast inflation in the US?
2. Build an appropriate time series model for US inflation, leveraging prior data in the selected countries (with a wide tsibble with each country as a column, we can add additional predictors to `ARIMA()` by name like we would in `lm()`):
  - This is known as adding exogenous variables to `ARIMA()` and behind the scenes the function will estimate a linear time series model with exogenous variables as predictors, using an `ARIMA()` model for the residuals
  - Estimate a model that you believe is appropriate after conducting your EDA.
  - Evaluate the model performance through diagnostic plots and making any necessary adjustments to satisfy key assumptions.

\newpage
### Q2 Part 3 

Contemporaneous correlation

USA–GBR = 0.83, USA–CAN = 0.88 → strong positive co-movement across all three countries.

Inflation rates rise and fall together, reflecting shared global shocks (oil prices, supply chain effects, etc.).

Cross-correlation functions (CCFs)

For GBR, the largest correlations appear at positive lags (12–60 months) → meaning GBR inflation tends to lead U.S. inflation by roughly 1 year or more.

For CAN, similar pattern but slightly stronger correlations at shorter leads (12–24 months).
→ Canadian inflation seems to anticipate U.S. inflation by about 1 year.

Economic intuition

Both the U.K. and Canada are open, commodity-linked economies affected by global factors earlier than the U.S.

These lead–lag patterns suggest that lagged GBR and CAN inflation can serve as useful predictors (exogenous regressors) for forecasting U.S. inflation.

Interpretation of CCFs

Both CCFs (GBR–USA and CAN–USA) show high positive correlation across nearly all lags, peaking at slightly positive lags.

In the convention used (ccf(GBR, USA)), positive lags mean GBR (or CAN) leads the USA.
→ Hence, inflation shocks in the U.K. and Canada tend to precede similar movements in the U.S. by roughly 6–12 months, consistent with your earlier table.

The correlations are persistently high (0.8–0.9), which indicates these economies are not just contemporaneously linked but also move together with a small lead of GBR and CAN.


Next I'll add lagged GBR and CAN inflation (say, 1-month and 12-month lags) as exogenous variables in an ARIMA model for the U.S.:

####After fitting the model


$$
USA_t = \alpha + \beta_0 GBR_{t-1} + \beta_1 CAN_{t-1} + \beta_2 GBR_{t-12} + \beta_2 CAN_{t-12} + \epsilon_t
$$
As shown by the report() for the fitted model, in the second code chunk below, **all coefficients have the expected signs and economically interpretable magnitudes in that short-run co-movement (positive) and long-run normalization (negative).**

In terms of model fit: 

AICc = −5332.7 and BIC = −5280.5, both lower than the earlier AR-only models. This is a significant improvement in explanatory power of the model.

The inclusion of foreign inflation terms and richer ARIMA errors drastically reduced the residual variance (sigma_squared is about 7.6 × 10⁻⁶). For Ljung-Box test the p-value is 2.12e-5, and we can reject the null of white-noise residuals.


**For diagnostics** 

Residuals are centered around zero, without visible trend, and variance looks stable.

The histogram shows that residuals are symmetric and bell-shaped.

The residual ACF shows that most lags within CI bounds, but spikes at every lag = 12 months. Together with the Ljung-Box test, the white-noise assumption is most likely not met (perhaps due to seasonality).

```{r}

# --- Q2 Part 3, Step 1: Cross-correlations USA vs GBR/CAN (training only) ---

# Keep the three series on the training range
train_wide <- train_data %>%
  select(date, USA, GBR, CAN) %>%
  as_tsibble(index = date)

# 1) Quick contemporaneous correlations
cont_corr <- train_wide %>%
  as_tibble() %>%
  summarise(
    cor_USA_GBR_0 = cor(USA, GBR, use = "complete.obs"),
    cor_USA_CAN_0 = cor(USA, CAN, use = "complete.obs")
  )
print(cont_corr)

# 2) Cross-correlation function (CCF) plots up to ±24 months
# Convention (stats::ccf default): positive lag means the FIRST argument leads the second
# e.g., ccf(x = GBR, y = USA, lag = +k) ⇒ GBR_t leads USA_t by k months.
ccf_gbr <- stats::ccf(x = train_wide$GBR, y = train_wide$USA, lag.max = 24, plot = FALSE, na.action = na.omit)
ccf_can <- stats::ccf(x = train_wide$CAN, y = train_wide$USA, lag.max = 24, plot = FALSE, na.action = na.omit)

# Helper to turn ccf object into a tidy table and show top lags by |corr|
to_tbl <- function(ccf_obj, who_leads, lag_max = 24, top_n = 8) {
  tibble(
    lag = as.integer(ccf_obj$lag * 12),   # convert to months if ts attributes present; safe cast here
    ccf = as.numeric(ccf_obj$acf)
  ) %>%
    arrange(desc(abs(ccf))) %>%
    mutate(interpretation = ifelse(lag > 0,
                                   paste0(who_leads, " leads USA by ", lag, " mo"),
                                   ifelse(lag < 0,
                                          paste0("USA leads ", who_leads, " by ", abs(lag), " mo"),
                                          "contemporaneous"))) %>%
    slice(1:top_n)
}

top_gbr <- to_tbl(ccf_gbr, "GBR")
top_can <- to_tbl(ccf_can, "CAN")

print(top_gbr)
print(top_can)

# 3) Optional base plots (nice for the report)
par(mfrow = c(1,2))
stats::ccf(train_wide$GBR, train_wide$USA, lag.max = 24, main = "CCF: GBR leads (+) / lags (−) vs USA")
stats::ccf(train_wide$CAN, train_wide$USA, lag.max = 24, main = "CCF: CAN leads (+) / lags (−) vs USA")
par(mfrow = c(1,1))

```


```{r}
# --- Q2 Part 3, Step 2: ARIMAX using GBR and CAN lags as exogenous regressors ---

# Create lagged predictors
train_exo <- train_data %>%
  mutate(
    GBR_lag1 = lag(GBR, 1),
    CAN_lag1 = lag(CAN, 1),
    GBR_lag12 = lag(GBR, 12),
    CAN_lag12 = lag(CAN, 12)
  ) %>%
  filter(!is.na(GBR_lag12))   # drop initial NAs

# Fit ARIMA with exogenous regressors
fit_arimax <- train_exo %>%
  model(ARIMA(USA ~ GBR_lag1 + CAN_lag1 + GBR_lag12 + CAN_lag12))

report(fit_arimax)

# Diagnostics
fit_arimax %>% gg_tsresiduals()
augment(fit_arimax) %>% features(.innov, ljung_box, lag = 12, dof = 8)

```

\newpage
## (3 points) Part-4: Forecasting and Model Comparison

Forecast inflation in 2022 and beyond (i.e. the test data) in the US using the various models you created. Include any models that did not necessarily satisfy the assumption of white noise in the residuals that you might have originally tried.

Which model is the best? Explain your results.

### Answer
Two models were estimated using the training data:

base_auto: a univariate ARIMA for U.S. inflation only.

arimax: an ARIMA with exogenous regressors (GBR and CAN inflation lags 1 and 12).



Out-of-sample forecast accuracy clearly favors the ARIMAX model:

RMSE ≈ 0.0107 vs 0.0130 (≈ 17 % improvement)

MAE ≈ 0.0079 vs 0.0114 (≈ 31 % improvement)

MAPE ≈ 11.2 % vs 20.2 %.

The information criteria are not directly comparable in magnitude (because the models use different likelihood structures), but both are strongly negative, implying good fit. Within each modeling framework, the ARIMAX model achieves far smaller residual variance (σ² ≈ 1.56 × 10⁻⁴ vs 7.81 × 10⁻⁶ for base_auto), suggesting that most systematic variation has been absorbed by the exogenous lags rather than left in the ARIMA errors.

Economic interpretation

Lagged inflation from Canada and the U.K. significantly improves prediction of U.S. inflation, consistent with the cross-correlation evidence that both countries tend to lead U.S. inflation by about 6–12 months. The positive short-lag coefficients (β₁ ≈ 0.26 for GBRₜ₋₁ and β₂ ≈ 0.69 for CANₜ₋₁) capture this short-term co-movement, while the small negative 12-month lags suggest long-run normalization.

The ARIMAX specification leveraging lagged foreign inflation provides superior forecasting performance for U.S. inflation relative to a univariate ARIMA.
This indicates that incorporating international price dynamics adds meaningful predictive power and produces more accurate out-of-sample forecasts.
```{r}
# --- Q2 Part 4: Forecasts & model comparison (baseline vs ARIMAX) ---

library(fable)
library(fabletools)

# 0) Rebuild lags on the FULL data so test rows have valid lag12 values
full_exo <- raw_inflation %>%
  select(date, USA, GBR, CAN) %>%
  mutate(date = as_date(date)) %>%
  as_tsibble(index = date) %>%
  mutate(
    GBR_lag1  = lag(GBR, 1),
    CAN_lag1  = lag(CAN, 1),
    GBR_lag12 = lag(GBR, 12),
    CAN_lag12 = lag(CAN, 12)
  )

# 1) Split into train/test using your split date
split_date <- ymd("2022-01-01")
train_exo <- full_exo %>% filter(date <  split_date) %>% filter(!is.na(GBR_lag12))
test_exo  <- full_exo %>% filter(date >= split_date) %>% filter(!is.na(GBR_lag12))

# 2) Fit two models on training data
fits <- model(
  train_exo,
  # (a) Baseline: automatic ARIMA on USA only (allows seasonal ARIMA)
  base_auto = ARIMA(USA),
  # (b) ARIMAX: add lagged GBR/CAN (short & annual)
  arimax    = ARIMA(USA ~ GBR_lag1 + CAN_lag1 + GBR_lag12 + CAN_lag12)
)

report(fits %>% select(arimax))
report(fits %>% select(base_auto))

# 3) Forecast over the test horizon
fc <- forecast(fits, new_data = test_exo)

# 4) Compare out-of-sample accuracy (test set only)
acc_test <- accuracy(fc, test_exo) %>%
  select(.model, RMSE, MAE, MAPE, MASE, AIC, AICc, BIC)

acc_test



# ---- Q2 Part 4: Forecasts & Model Comparison (baseline ARIMA vs ARIMAX) ----

library(tsibble)
library(fable)
library(fabletools)
library(lubridate)
library(dplyr)
library(tidyr)

# 0) Start from your existing 'inflation_arimax_data' (already a tsibble with date=yearmonth)
#    Ensure it is monthly-regular and fill implicit gaps before creating lags.
full_exo <- inflation_arimax_data %>%
  arrange(date) %>%
  fill_gaps() %>%                      # <-- resolves implicit gaps
  mutate(
    GBR_lag1  = dplyr::lag(GBR, 1),
    CAN_lag1  = dplyr::lag(CAN, 1),
    GBR_lag12 = dplyr::lag(GBR, 12),
    CAN_lag12 = dplyr::lag(CAN, 12)
  )

# 1) Split with a monthly cut (use yearmonth to match your index)
split_month <- yearmonth("2022-01")

train_exo <- full_exo %>%
  filter(date < split_month) %>%
  drop_na(USA)  # keep USA observed; exog NAs will be dropped automatically by ARIMA()

test_exo <- full_exo %>%
  filter(date >= split_month) %>%
  drop_na(USA, GBR_lag1, CAN_lag1, GBR_lag12, CAN_lag12)  # ensure exogs available in test

# 2) Fit models (on the regularized training tsibble)
fits <- model(
  train_exo,
  base_auto = ARIMA(USA),                                            # univariate baseline
  arimax    = ARIMA(USA ~ GBR_lag1 + CAN_lag1 + GBR_lag12 + CAN_lag12)  # uses exogenous lags
)

# Optional: detailed summary for ARIMAX
report(fits %>% select(arimax))
glance(fits)

# 3) Forecast on the test horizon (fable will use exogenous values from test_exo)
fc <- forecast(fits, new_data = test_exo)


# 4) Compare out-of-sample accuracy (test set only)
acc_test <- accuracy(fc, test_exo) %>%
  select(.model, RMSE, MAE, MAPE, MASE)

acc_test

info_criteria <- glance(fits) %>%
  select(.model, AIC, AICc, BIC)

info_criteria

```